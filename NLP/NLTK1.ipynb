{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Tokenization is the process by which a large quantity of text is divided into smaller parts called tokens. These tokens are very useful for finding patterns and are considered as a base step for stemming and lemmatization. Tokenization also helps to substitute sensitive data elements with non-sensitive data elements.<br>\n",
    "Natural language processing is used for building applications such as Text classification, intelligent chatbot, sentimental analysis, language translation, etc. It becomes vital to understand the pattern in the text to achieve the above-stated purpose.<br>\n",
    "Natural Language toolkit has very important module NLTK tokenize sentences which further comprises of sub-modules\n",
    "1. word tokenize\n",
    "2. sentence tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cmudict', 'cmudict.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'inaugural', 'inaugural.zip', 'movie_reviews', 'movie_reviews.zip', 'names', 'names.zip', 'omw', 'omw.zip', 'shakespeare', 'shakespeare.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'wordnet', 'wordnet.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "emma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Emma by Jane Austen 1816 ] VOLUME I CHAPTER I Emma Woodhouse , handsome , clever , and rich , with a comfortable home and happy disposition , seemed to unite some of the best blessings of existence ; and had lived nearly twenty - one years in the world with very little to distress or vex her . She was the youngest of the two daughters of a most affectionate , indulgent father ; and had , in consequence of her sister ' s marriage , been mistress of his house from a very early period . Her mother had died too long ago for her to have more than an indistinct remembrance of her caresses ; and her place had been supplied by an excellent woman as governess , who had fallen little short of a mother in affection . Sixteen years had Miss Taylor been in Mr . Woodhouse ' s family , less as a governess than a friend , very fond of both daughters , but particularly of Emma . Between _them_ it was more the intimacy of sisters . Even before Miss Taylor had ceased to hold the nominal office of governess , the mildness of her temper had hardly allowed her to impose any restraint ; and the shadow of authority being now long passed away , they had been living together as friend and friend very mutually attached , and Emma doing just what she liked ; highly esteeming Miss Taylor ' s judgment , but directed chiefly by her own . The real evils , indeed , of Emma ' s situation were the power of having rather too much her own way , and a disposition to think a little too well of herself ; these were the disadvantages which threatened alloy to her many enjoyments . The danger , however , was at present so unperceived , that they did not by any means rank as misfortunes with her . Sorrow came -- a gentle sorrow -- but not at all in the shape of any disagreeable consciousness .-- Miss Taylor married . It was Miss Taylor ' s loss which first brought grief . It was on the wedding - day of this beloved friend that Emma first sat in mournful thought of any continuance . The wedding over , and the bride - people gone , her father and herself were left to dine together , with no prospect of a third to cheer a long evening . Her father composed himself to sleep after dinner , as usual , and she had then only to sit and think of what she had lost . The event had every promise of happiness for her friend . Mr . Weston was a man of unexceptionable character , easy fortune , suitable age , and pleasant manners ; and there was some satisfaction in considering with what self - denying , generous friendship she had always wished and "
     ]
    }
   ],
   "source": [
    "for word in emma[:500]:\n",
    "    print(word, sep = ' ', end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI = \"\"\"According to the father of Artificial Intelligence, John McCarthy, it is “The science and engineering of making intelligent machines, especially intelligent computer programs”.\n",
    "\n",
    "Artificial Intelligence is a way of making a computer, a computer-controlled robot, or a software think intelligently, in the similar manner the intelligent humans think.\n",
    "\n",
    "AI is accomplished by studying how human brain thinks, and how humans learn, decide, and work while trying to solve a problem, and then using the outcomes of this study as a basis of developing intelligent software and systems.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['According', 'to', 'the', 'father', 'of', 'Artificial', 'Intelligence', ',', 'John', 'McCarthy', ',', 'it', 'is', '“', 'The', 'science', 'and', 'engineering', 'of', 'making', 'intelligent', 'machines', ',', 'especially', 'intelligent', 'computer', 'programs', '”', '.', 'Artificial', 'Intelligence', 'is', 'a', 'way', 'of', 'making', 'a', 'computer', ',', 'a', 'computer-controlled', 'robot', ',', 'or', 'a', 'software', 'think', 'intelligently', ',', 'in', 'the', 'similar', 'manner', 'the', 'intelligent', 'humans', 'think', '.', 'AI', 'is', 'accomplished', 'by', 'studying', 'how', 'human', 'brain', 'thinks', ',', 'and', 'how', 'humans', 'learn', ',', 'decide', ',', 'and', 'work', 'while', 'trying', 'to', 'solve', 'a', 'problem', ',', 'and', 'then', 'using', 'the', 'outcomes', 'of', 'this', 'study', 'as', 'a', 'basis', 'of', 'developing', 'intelligent', 'software', 'and', 'systems', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(AI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization of Sentences\n",
    "Sub-module available for the above is sent_tokenize. An obvious question in your mind would be why sentence tokenization is needed when we have the option of word tokenization. Imagine you need to count average words per sentence, how you will calculate? For accomplishing such a task, you need both NLTK sentence tokenizer as well as NLTK word tokenizer to calculate the ratio. Such output serves as an important feature for machine training as the answer would be numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All work and no play makes jack dull boy.', 'All work and no play makes jack a dull boy.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    " \n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    "print(sent_tokenize(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK and arrays\n",
    "If you wish to you can store the words and sentences in arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All work and no play makes jack dull boy.', 'All work and no play makes jack a dull boy.']\n",
      "['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'dull', 'boy', '.', 'All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    " \n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    " \n",
    "phrases = sent_tokenize(data)\n",
    "words = word_tokenize(data)\n",
    " \n",
    "print(phrases)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK stop words\n",
    "\n",
    "Natural language processing (nlp) is a research field that presents many challenges such as natural language understanding.\n",
    "Text may contain stop words like ‘the’, ‘is’, ‘are’. Stop words can be filtered from the text to be processed. There is no universal list of stop words in nlp research, however the nltk module contains a list of stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'work', 'play', 'makes', 'jack', 'dull', 'boy', '.', 'All', 'work', 'play', 'makes', 'jack', 'dull', 'boy', '.']\n"
     ]
    }
   ],
   "source": [
    "# The code abobe is modified to this\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    "stopWords = set(stopwords.words('english'))\n",
    "words = word_tokenize(data)\n",
    "wordsFiltered = []\n",
    " \n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    " \n",
    "print(wordsFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "{'you', 'shan', 'on', 'its', \"you'll\", 'ours', 'myself', 'hadn', 'any', 'themselves', 'an', \"wouldn't\", \"isn't\", 'them', 'out', 'be', \"hasn't\", 'won', 'they', 'while', 'yourself', 'am', 'haven', 'each', 'your', 'himself', 'being', 'have', 'from', \"didn't\", 'he', 'but', 'don', 'before', 'again', 'further', 'than', 'will', 'few', 'y', \"shan't\", \"haven't\", 's', 'can', 'm', 'and', 'when', 'mightn', 'yourselves', 'ain', 'by', 'no', 'this', 'has', 'having', 'wouldn', 'because', \"she's\", 'how', 'been', 'so', 'his', 'her', 'it', 'during', 'once', 'both', 'aren', 'couldn', 'of', 'isn', 'very', 'against', 'is', 'theirs', 'up', 'didn', 'that', 'now', \"hadn't\", 'off', 'such', 'wasn', 'then', 'yours', 'me', 'do', 'should', \"mustn't\", \"it's\", 'itself', 'here', 'as', 'other', 'whom', 'above', 'not', 'over', 'what', 'weren', 'which', \"you've\", \"won't\", \"doesn't\", 'under', \"shouldn't\", 'nor', 'shouldn', 'hers', 'their', 'at', 'there', 'or', 'between', 'the', 'more', \"you're\", \"mightn't\", 'we', 'just', 'own', 'i', 'had', \"needn't\", 'below', 'where', 'ma', 'in', 'mustn', 'why', 'all', 'were', \"don't\", 'to', \"couldn't\", 've', 'was', 'ourselves', 'll', 'my', 'd', 'these', 'a', 'into', 'did', 're', 'most', 'too', 't', \"aren't\", 'o', 'herself', 'our', 'down', 'only', 'for', 'about', 'she', 'until', 'with', 'those', 'hasn', 'some', 'needn', \"weren't\", 'him', \"you'd\", 'same', 'does', 'if', 'after', 'doing', 'through', 'doesn', 'who', \"that'll\", \"wasn't\", \"should've\", 'are'}\n"
     ]
    }
   ],
   "source": [
    "print(len(stopWords))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK – stemming\n",
    "A word stem is part of a word. It is sort of a normalization idea, but linguistic.\n",
    "For example, the stem of the word waiting is wait.\n",
    "![](word-stem.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"game\",\"gaming\",\"gamed\",\"games\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game\n",
      "game\n",
      "game\n",
      "game\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    " \n",
    "for word in words:\n",
    "    print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word stemming for sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaming:game\n",
      ",:,\n",
      "the:the\n",
      "gamers:gamer\n",
      "play:play\n",
      "games:game\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    " \n",
    "ps = PorterStemmer()\n",
    " \n",
    "sentence = \"gaming, the gamers play games\"\n",
    "words = word_tokenize(sentence)\n",
    " \n",
    "for word in words:\n",
    "    print(word + \":\" + ps.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK speech tagging\n",
    "The module NLTK can automatically tag speech.\n",
    "Given a sentence or paragraph, it can label words such as verbs, nouns and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Whether', 'IN'), ('you', 'PRP'), (\"'re\", 'VBP'), ('new', 'JJ'), ('to', 'TO'), ('programming', 'VBG'), ('or', 'CC'), ('an', 'DT'), ('experienced', 'JJ'), ('developer', 'NN'), (',', ','), ('it', 'PRP'), (\"'s\", 'VBZ'), ('easy', 'JJ'), ('to', 'TO'), ('learn', 'VB'), ('and', 'CC'), ('use', 'VB'), ('Python', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    " \n",
    "document = 'Whether you\\'re new to programming or an experienced developer, it\\'s easy to learn and use Python.'\n",
    "sentences = nltk.sent_tokenize(document)   \n",
    "for sent in sentences:\n",
    "    print(nltk.pos_tag(nltk.word_tokenize(sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the second element of the tuple is the class.\n",
    "The meanings of these speech codes are shown in the table below:\n",
    "![](nltk-speech-codes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Netherlands', 'NNP')\n",
      "('King', 'NNP')\n",
      "('Day', 'NNP')\n",
      "('San', 'NNP')\n",
      "('Francisco', 'NNP')\n"
     ]
    }
   ],
   "source": [
    "# We can filter this data based on the type of word:\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    " \n",
    "document = 'Today the Netherlands celebrates King\\'s Day. To honor this tradition, the Dutch embassy in San Francisco invited me to'\n",
    "sentences = nltk.sent_tokenize(document)   \n",
    " \n",
    "data = []\n",
    "for sent in sentences:\n",
    "    data = data + nltk.pos_tag(nltk.word_tokenize(sent))\n",
    " \n",
    "for word in data: \n",
    "    if 'NNP' in word[1]: \n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing – prediction\n",
    "We can use natural language processing to make predictions.\n",
    "Example: Given a product review, a computer can predict if its positive or negative based on the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nlp prediction example\n",
    "Given a name, the classifier will predict if it’s a male or female.<br>\n",
    "To create our analysis program, we have several steps:\n",
    "1. Data preparation\n",
    "2. Feature extraction\n",
    "3. Training\n",
    "4. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "The first step is to prepare data.\n",
    "We use the names set included with nltk.\n",
    "![](nltk_downloader.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    " \n",
    "# Load data and training \n",
    "names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "\t [(name, 'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is simply a collection of tuples. To give you an idea of what the dataset looks like:\n",
    "<br />\n",
    "<table><tr><td bgcolor='pink' align='left'>\n",
    "[(u'Aaron', 'male'), (u'Abbey', 'male'), (u'Abbie', 'male')]<br />\n",
    "[(u'Zorana', 'female'), (u'Zorina', 'female'), (u'Zorine', 'female')]\n",
    "    </td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "Based on the dataset, we prepare our feature. The feature we will use is the last letter of a name:\n",
    "We define a featureset using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word): \n",
    "    return {'last_letter': word[-1]}\n",
    "featuresets = [(gender_features(n), g) for (n,g) in names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and prediction\n",
    "We train and predict using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n"
     ]
    }
   ],
   "source": [
    "train_set = featuresets\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
    " \n",
    "# Predict\n",
    "print(classifier.classify(gender_features('Frank')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Anand\n",
      "male\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "name = input(\"Name: \")\n",
    "print(classifier.classify(gender_features(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
